{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 2 — Feature Analysis & Ablation\n",
        "\n",
        "**CSP-Ablation-Project** · T1–T5\n",
        "\n",
        "Builds on Phase 1 probe. Pipeline:\n",
        "- **T1** Probe weight extraction & feature ranking\n",
        "- **T2** Feature activation profiling (AUC, histograms)\n",
        "- **T3** Ablation engine (zero + mean)\n",
        "- **T4** Ablation threshold sweep → ablation curve\n",
        "- **T5** Generation sanity check (original vs ablated)\n",
        "\n",
        "**Prerequisite:** Run `phase1_probing.ipynb` first. Artifacts in `DATA/CSP-Ablation-Project/artifacts/`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run ONCE, then: Runtime → Restart session. Skip afterwards.\n",
        "#!pip install -q torch transformers accelerate scikit-learn matplotlib pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, json, pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
        "CODE_DIR   = os.path.join(DRIVE_ROOT, \"CODE\", \"CSP-Ablation-Project\")\n",
        "DATA_DIR   = os.path.join(DRIVE_ROOT, \"DATA\", \"CSP-Ablation-Project\")\n",
        "SPRINT, VERSION = \"sprint1\", \"v1.0\"\n",
        "\n",
        "if not os.path.isdir(CODE_DIR):\n",
        "    !git clone https://github.com/piotrwilam/CSP-Ablation-Project.git \"{CODE_DIR}\"\n",
        "else:\n",
        "    !cd \"{CODE_DIR}\" && git pull\n",
        "\n",
        "if CODE_DIR not in sys.path:\n",
        "    sys.path.insert(0, CODE_DIR)\n",
        "\n",
        "from src.config import artifacts_dir\n",
        "ARTIFACTS = artifacts_dir(SPRINT, VERSION)\n",
        "# Fallback: legacy flat artifacts (if phase1 ran before versioning)\n",
        "if not os.path.exists(os.path.join(ARTIFACTS, \"code_vuln_probe.pkl\")):\n",
        "    legacy = os.path.join(DATA_DIR, \"artifacts\")\n",
        "    if os.path.exists(os.path.join(legacy, \"code_vuln_probe.pkl\")):\n",
        "        ARTIFACTS = legacy\n",
        "        print(\"Using legacy artifacts path\")\n",
        "\n",
        "print(f\"ARTIFACTS: {ARTIFACTS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Phase 1 artifacts\n",
        "with open(os.path.join(ARTIFACTS, \"code_vuln_probe.pkl\"), \"rb\") as f:\n",
        "    probe_dump = pickle.load(f)\n",
        "probe = probe_dump[\"probe\"]\n",
        "scaler = probe_dump[\"scaler\"]\n",
        "PROBE_LAYER = probe_dump[\"probe_layer\"]\n",
        "\n",
        "X = np.load(os.path.join(ARTIFACTS, \"X_train.npy\"))\n",
        "y = np.load(os.path.join(ARTIFACTS, \"y_train.npy\"))\n",
        "\n",
        "print(f\"Probe layer: {PROBE_LAYER} | X: {X.shape} | y: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## T1. Probe Weight Extraction & Feature Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights = probe.coef_[0]\n",
        "n_features = len(weights)\n",
        "\n",
        "# Rank by magnitude\n",
        "order = np.argsort(np.abs(weights))[::-1]\n",
        "ranks = np.empty_like(order)\n",
        "ranks[order] = np.arange(n_features)\n",
        "\n",
        "# Top-20 positive (insecurity-associated) and top-20 negative (security-associated)\n",
        "pos_idx = np.where(weights > 0)[0]\n",
        "neg_idx = np.where(weights < 0)[0]\n",
        "top20_pos = pos_idx[np.argsort(weights[pos_idx])[::-1][:20]] if len(pos_idx) > 0 else np.array([])\n",
        "top20_neg = neg_idx[np.argsort(weights[neg_idx])[:20]] if len(neg_idx) > 0 else np.array([])\n",
        "\n",
        "top_features = {\n",
        "    \"top20_insecurity\": [{\"idx\": int(i), \"weight\": float(weights[i]), \"rank\": int(ranks[i])} for i in top20_pos],\n",
        "    \"top20_security\": [{\"idx\": int(i), \"weight\": float(weights[i]), \"rank\": int(ranks[i])} for i in top20_neg],\n",
        "    \"n_features\": n_features,\n",
        "    \"weight_stats\": {\n",
        "        \"mean_abs\": float(np.mean(np.abs(weights))),\n",
        "        \"std\": float(np.std(weights)),\n",
        "        \"max\": float(np.max(weights)),\n",
        "        \"min\": float(np.min(weights)),\n",
        "    },\n",
        "}\n",
        "\n",
        "with open(os.path.join(ARTIFACTS, \"top_features.json\"), \"w\") as f:\n",
        "    json.dump(top_features, f, indent=2)\n",
        "\n",
        "print(\"Top 5 insecurity-associated:\", [f\"{t['idx']}:{t['weight']:.4f}\" for t in top_features[\"top20_insecurity\"][:5]])\n",
        "print(\"Top 5 security-associated:\", [f\"{t['idx']}:{t['weight']:.4f}\" for t in top_features[\"top20_security\"][:5]])\n",
        "print(f\"Saved → {ARTIFACTS}/top_features.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Weight distribution histogram\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "ax.hist(np.abs(weights), bins=80, edgecolor=\"black\", alpha=0.7)\n",
        "ax.set_xlabel(\"|Weight|\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_title(\"Probe weight magnitude distribution (is signal concentrated or spread?)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(ARTIFACTS, \"weight_distribution_histogram.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(f\"Saved → {ARTIFACTS}/weight_distribution_histogram.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## T2. Feature Activation Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All 40 top features (20 pos + 20 neg)\n",
        "all_top_idx = list(top20_pos) + list(top20_neg)\n",
        "\n",
        "# Per-feature AUC\n",
        "aucs = []\n",
        "for idx in all_top_idx:\n",
        "    act = X[:, idx]\n",
        "    if len(np.unique(y)) < 2:\n",
        "        aucs.append(0.5)\n",
        "        continue\n",
        "    auc = roc_auc_score(y, act)\n",
        "    aucs.append(auc)\n",
        "\n",
        "auc_table = pd.DataFrame({\n",
        "    \"feature_idx\": all_top_idx,\n",
        "    \"weight\": [float(weights[i]) for i in all_top_idx],\n",
        "    \"auc\": aucs,\n",
        "})\n",
        "auc_table = auc_table.sort_values(\"auc\", ascending=False).reset_index(drop=True)\n",
        "auc_table.to_csv(os.path.join(ARTIFACTS, \"per_feature_auc.csv\"), index=False)\n",
        "print(auc_table.head(10))\n",
        "print(f\"\\nSaved → {ARTIFACTS}/per_feature_auc.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 5 most discriminative (by AUC) — overlapping histograms\n",
        "top5_idx = auc_table.head(5)[\"feature_idx\"].tolist()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 7))\n",
        "axes = axes.flatten()\n",
        "for i, idx in enumerate(top5_idx):\n",
        "    ax = axes[i]\n",
        "    secure = X[y == 0, idx]\n",
        "    insecure = X[y == 1, idx]\n",
        "    ax.hist(secure, bins=25, alpha=0.6, label=\"Secure\", color=\"green\", density=True)\n",
        "    ax.hist(insecure, bins=25, alpha=0.6, label=\"Insecure\", color=\"red\", density=True)\n",
        "    ax.set_xlabel(f\"Feature {idx} activation\")\n",
        "    ax.set_ylabel(\"Density\")\n",
        "    auc_val = auc_table[auc_table[\"feature_idx\"] == idx][\"auc\"].values[0]\n",
        "    ax.set_title(f\"Feature {idx} (AUC={auc_val:.3f})\")\n",
        "    ax.legend()\n",
        "axes[-1].axis(\"off\")\n",
        "plt.suptitle(\"Top 5 discriminative features: Secure vs Insecure activation distributions\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(ARTIFACTS, \"activation_histograms_top5.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(f\"Saved → {ARTIFACTS}/activation_histograms_top5.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## T3. Ablation Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.model_loader import load_model_and_tokenizer\n",
        "from src.ablation import CircuitAblator\n",
        "from src.hidden_states import collect_resid_all_layers\n",
        "from src.data_loader import load_minimal_pairs, prompt_from_scenario\n",
        "\n",
        "model, tokenizer, layers = load_model_and_tokenizer()\n",
        "device = next(model.parameters()).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test ablation on 3–5 examples\n",
        "from src.data_utils import get_dataset_path\n",
        "PAIRS_PATH = get_dataset_path(SPRINT, CODE_DIR, DATA_DIR)\n",
        "examples = load_minimal_pairs(PAIRS_PATH)[:5]\n",
        "\n",
        "# Extract hidden states without ablation\n",
        "all_data = collect_resid_all_layers(examples, model, tokenizer, layers, max_samples=5)\n",
        "X_orig, y_orig = all_data[PROBE_LAYER]\n",
        "\n",
        "# Zero-ablate top-5 features\n",
        "top5_ablate = [t[\"idx\"] for t in top_features[\"top20_insecurity\"][:5]]\n",
        "ablator = CircuitAblator(layers[PROBE_LAYER], PROBE_LAYER, top5_ablate, strategy=\"zero\")\n",
        "ablator.enable()\n",
        "all_data_abl = collect_resid_all_layers(examples, model, tokenizer, layers, max_samples=5)\n",
        "ablator.disable()\n",
        "X_abl, y_abl = all_data_abl[PROBE_LAYER]\n",
        "\n",
        "# Compare: ablated features should be zero\n",
        "for idx in top5_ablate:\n",
        "    print(f\"Feature {idx}: orig mean={X_orig[:, idx].mean():.4f}, ablated mean={X_abl[:, idx].mean():.6f}\")\n",
        "print(\"\\nAblation engine OK.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## T4. Ablation Threshold Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top features by |weight| (combined ranking)\n",
        "order = np.argsort(np.abs(weights))[::-1]\n",
        "\n",
        "k_values = [1, 3, 5, 10, 20, 50, 100, 200]\n",
        "results = []\n",
        "\n",
        "X_s = scaler.transform(X)\n",
        "acc_baseline = probe.score(X_s, y)\n",
        "print(f\"Baseline probe accuracy (no ablation): {acc_baseline:.2%}\")\n",
        "\n",
        "for k in k_values:\n",
        "    indices = order[:k].tolist()\n",
        "    X_abl = X.copy()\n",
        "    X_abl[:, indices] = 0\n",
        "    X_abl_s = scaler.transform(X_abl)\n",
        "    acc = probe.score(X_abl_s, y)\n",
        "    results.append({\"k\": k, \"accuracy\": float(acc)})\n",
        "    print(f\"  k={k:>3}: {acc:.2%}\")\n",
        "\n",
        "with open(os.path.join(ARTIFACTS, \"ablation_sweep_results.json\"), \"w\") as f:\n",
        "    json.dump({\"baseline\": acc_baseline, \"sweep\": results}, f, indent=2)\n",
        "print(f\"\\nSaved → {ARTIFACTS}/ablation_sweep_results.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ablation curve plot\n",
        "ks = [r[\"k\"] for r in results]\n",
        "accs = [r[\"accuracy\"] for r in results]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "ax.plot(ks, accs, \"o-\", linewidth=2, markersize=8)\n",
        "ax.axhline(acc_baseline, color=\"gray\", linestyle=\"--\", alpha=0.7, label=\"Baseline\")\n",
        "ax.axhline(0.5, color=\"red\", linestyle=\":\", alpha=0.5, label=\"Chance\")\n",
        "ax.set_xlabel(\"Number of ablated features (k)\")\n",
        "ax.set_ylabel(\"Probe accuracy\")\n",
        "ax.set_title(\"Ablation curve: probe accuracy vs top-k zero ablation\")\n",
        "ax.legend()\n",
        "ax.set_ylim(0.4, 1.05)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(ARTIFACTS, \"ablation_curve.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(f\"Saved → {ARTIFACTS}/ablation_curve.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## T5. Generation Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick optimal k from T4 (smallest k with notable accuracy drop)\n",
        "OPTIMAL_K = 20  # or derive from sweep: first k where acc < baseline - 0.05\n",
        "for r in results:\n",
        "    if r[\"accuracy\"] < acc_baseline - 0.05:\n",
        "        OPTIMAL_K = r[\"k\"]\n",
        "        break\n",
        "print(f\"Using k={OPTIMAL_K} for ablation.\")\n",
        "\n",
        "# Build 40 prompts from minimal pairs (20 insecure, 20 secure)\n",
        "with open(PAIRS_PATH) as f:\n",
        "    pairs = json.load(f)\n",
        "\n",
        "prompts_insecure = []\n",
        "prompts_secure = []\n",
        "for p in pairs:\n",
        "    if len(prompts_insecure) < 20:\n",
        "        # Use ~70% of corrupted code as prompt (model completes the rest)\n",
        "        code = p[\"corrupted\"]\n",
        "        cut = max(1, int(len(code) * 0.7))\n",
        "        prompts_insecure.append(code[:cut])\n",
        "    if len(prompts_secure) < 20:\n",
        "        code = p[\"clean\"]\n",
        "        cut = max(1, int(len(code) * 0.7))\n",
        "        prompts_secure.append(code[:cut])\n",
        "    if len(prompts_insecure) >= 20 and len(prompts_secure) >= 20:\n",
        "        break\n",
        "\n",
        "prompts = prompts_insecure + prompts_secure\n",
        "labels = [\"insecure\"] * 20 + [\"secure\"] * 20\n",
        "print(f\"{len(prompts)} prompts ({len(prompts_insecure)} insecure, {len(prompts_secure)} secure)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "GEN_MAX_NEW = 50\n",
        "top_k_indices = order[:OPTIMAL_K].tolist()\n",
        "\n",
        "# Ablator for generation\n",
        "ablator = CircuitAblator(layers[PROBE_LAYER], PROBE_LAYER, top_k_indices, strategy=\"zero\")\n",
        "\n",
        "outputs_orig = []\n",
        "outputs_abl = []\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    enc = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=400).to(device)\n",
        "    input_ids = enc[\"input_ids\"]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        out_orig = model.generate(input_ids, max_new_tokens=GEN_MAX_NEW, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
        "    \n",
        "    ablator.enable()\n",
        "    with torch.no_grad():\n",
        "        out_abl = model.generate(input_ids, max_new_tokens=GEN_MAX_NEW, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
        "    ablator.disable()\n",
        "    \n",
        "    text_orig = tokenizer.decode(out_orig[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
        "    text_abl = tokenizer.decode(out_abl[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
        "    outputs_orig.append(text_orig)\n",
        "    outputs_abl.append(text_abl)\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  {i+1}/{len(prompts)} done\")\n",
        "\n",
        "print(\"Generation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Side-by-side comparison table\n",
        "df = pd.DataFrame({\n",
        "    \"label\": labels,\n",
        "    \"prompt_preview\": [p[:60] + \"...\" if len(p) > 60 else p for p in prompts],\n",
        "    \"original_output\": outputs_orig,\n",
        "    \"ablated_output\": outputs_abl,\n",
        "})\n",
        "df.to_csv(os.path.join(ARTIFACTS, \"generation_comparison.csv\"), index=False)\n",
        "df.head(10)\n",
        "print(f\"\\nFull table saved → {ARTIFACTS}/generation_comparison.csv\")\n",
        "\n",
        "# Push all Phase 2 artifacts to Hugging Face\n",
        "from src.utils import save_to_hub\n",
        "from src.config import HF_REPO_ID\n",
        "hf_prefix = f\"artifacts/{SPRINT}/{VERSION}\"\n",
        "for f in os.listdir(ARTIFACTS):\n",
        "    p = os.path.join(ARTIFACTS, f)\n",
        "    if os.path.isfile(p):\n",
        "        save_to_hub(p, f\"{hf_prefix}/{f}\", HF_REPO_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## T5. Notes (manual)\n",
        "\n",
        "Review `generation_comparison.csv` and note:\n",
        "- Does the ablated model still produce coherent code?\n",
        "- Does it avoid insecure patterns more often?\n",
        "- Any obvious breakage or degradation?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
